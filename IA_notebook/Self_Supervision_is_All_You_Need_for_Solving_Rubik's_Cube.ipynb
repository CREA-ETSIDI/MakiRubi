{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usYEPOiQZn5t"
   },
   "source": [
    "# **Self-Supervision is All You Need for Solving Rubik's Cube**\n",
    "\n",
    "**Date created:** 2022/01/27<br>\n",
    "**Last modified:** 2022/08/13<br>\n",
    "\n",
    "---\n",
    "## **Description**\n",
    "\n",
    "This notebook is intended to demonstrate the proposed method and to allow for reproducible experiments.\n",
    "\n",
    "For the purpose of demonstration, the number of training steps is set to $10000$ and the beam width is set to $2^{12}$ by default.\n",
    "If you want to replicate our best reported result, set ```TrainConfig.num_train_steps``` to $1000000$ and ```top_k``` to $2^{18}$. Note, however, that it will take several days to finish both training and inference.\n",
    "\n",
    "## **Training & Inference**\n",
    "\n",
    "The DNN is trained to predict the last move of a scramble based on the corresponding problem state. In inference, the inverse of the predicted last move is applied to the given state.\n",
    "\n",
    "## **Test**\n",
    "\n",
    "The trained model is evaluated on [1,000 test cases provided by Forest Agostinelli, et al. (2019)](https://github.com/forestagostinelli/DeepCubeA/) and compared to the result of DeepCubeA and an optimal solver in three respects: a) solution lengths, b) number of nodes, and c) computation time.\n",
    "\n",
    "---\n",
    "### ***Q. How much time does this notebook take?***\n",
    "\n",
    "For reference, with one 4-core CPU and one GPU ([NVIDIA Tesla P100 PCIe 16GB](https://images.nvidia.com/content/tesla/pdf/nvidia-tesla-p100-PCIe-datasheet.pdf)), it took **about 3 hours** to run the entire notebook, including training, inference, and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p03YuJ_5Zn5w"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxS097YYZn5x"
   },
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yrnE4BBvZn5z"
   },
   "outputs": [],
   "source": [
    "# problem\n",
    "METRIC = \"QTM\"\n",
    "SCRAMBLE_LENGTH = {\"QTM\": 26, \"HTM\": 20}[METRIC]\n",
    "# training\n",
    "class TrainConfig:\n",
    "    learning_rate = 1e-3\n",
    "    batch_size_per_depth = 1000\n",
    "    num_train_steps = 1000000\n",
    "    interval_steps_save = 1000\n",
    "    interval_steps_plot = 100\n",
    "    scramble_length = SCRAMBLE_LENGTH\n",
    "\n",
    "# inference\n",
    "## The wider the beam search, the more time required, but the shorter the solution.\n",
    "top_k = 2**10\n",
    "## This can be any number greater than or equal to the Gods Number.\n",
    "max_depth = SCRAMBLE_LENGTH * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eQ69yzUZn52"
   },
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qBHA9qgZn53",
    "outputId": "03138557-a8f3-42b3-df11-f06bb01554b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "multiprocessing.cpu_count(): 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"nvidia-smi\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'device: {device}')\n",
    "print(f'multiprocessing.cpu_count(): {multiprocessing.cpu_count()}')\n",
    "!nvidia-smi -L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxaPcdlaZn55"
   },
   "source": [
    "pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "Xxljm49jZn56"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = cycler(\n",
    "    color=[\"#212121\", \"#2180FE\", \"#EB4275\"])\n",
    "\n",
    "\n",
    "def plt_history(h):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=[4, 4])\n",
    "    axes.plot(h)\n",
    "    axes.set_xscale(\"log\")\n",
    "    axes.set_title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def regression_coef(x, y):\n",
    "    coef = np.array(y) / np.array(x)\n",
    "    coef = np.mean(np.squeeze(coef))\n",
    "    return coef\n",
    "\n",
    "\n",
    "def plot_result(solutions_all, num_nodes_all, times_all):\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(16, 9))\n",
    "    ax = ax.ravel()\n",
    "    for i, result in enumerate([solutions_all, num_nodes_all, times_all]):\n",
    "        result = [e for e in result if e is not None]\n",
    "        if i == 0:  # soltions\n",
    "            result = [len(e) for e in result if e is not None]\n",
    "            ax[i].axvline(\n",
    "                np.mean(result),\n",
    "                color=\"#00ffff\",\n",
    "                label=f\"mean={round(np.mean(result),3)}\",\n",
    "            )\n",
    "            result = {i: result.count(i)\n",
    "                      for i in range(min(result), max(result) + 1)}\n",
    "            ax[i].bar(\n",
    "                result.keys(),\n",
    "                result.values(),\n",
    "                width=1.0,\n",
    "                label=f\"Success: {len([len(e) for e in solutions_all if e is not None])}/{len(solutions_all)}\",\n",
    "            )\n",
    "            ax[i].legend()\n",
    "            ax[i].set_xlabel(\"Solution length\")\n",
    "            ax[i].set_ylabel(\"Frequency\")\n",
    "        else:\n",
    "            ax[i].hist(result)\n",
    "            ax[i].axvline(\n",
    "                np.mean(result),\n",
    "                color=\"#00ffff\",\n",
    "                label=f\"mean={round(np.mean(result),3)}\",\n",
    "            )\n",
    "            ax[i].legend()\n",
    "            if i == 1:\n",
    "                ax[i].set_xlabel(\"No. of nodes\")\n",
    "            else:\n",
    "                ax[i].set_xlabel(\"Calculation time (s)\")\n",
    "\n",
    "    solution_lengths, num_nodes, times = [\n",
    "        [e for e in result if e is not None]\n",
    "        for result in [solutions_all, num_nodes_all, times_all]\n",
    "    ]\n",
    "    solution_lengths = [len(e) for e in solution_lengths]\n",
    "\n",
    "    for (xlabel, ylabel), (x, y) in [\n",
    "        [(\"Solution lengths\", \"No. of nodes\"), (solution_lengths, num_nodes)],\n",
    "        [(\"No. of nodes\", \"Calculation time (s)\"), (num_nodes, times)],\n",
    "        [(\"Calculation time (s)\", \"Solution lengths\"), (times, solution_lengths)],\n",
    "    ]:\n",
    "        i += 1\n",
    "        ax[i].set_xlabel(xlabel)\n",
    "        ax[i].set_ylabel(ylabel)\n",
    "        x_range = np.linspace(0, max(x), 100)\n",
    "        ax[i].plot(\n",
    "            x_range,\n",
    "            x_range * regression_coef(x, y),\n",
    "            label=f\"slope={round(regression_coef(x, y), 5)}\",\n",
    "            color=\"#00ffff\",\n",
    "        )\n",
    "        ax[i].scatter(x, y)\n",
    "        ax[i].legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8ItwXquZn59"
   },
   "source": [
    "## Rubik's Cube\n",
    "Rubik's Cube is operated based on the locations and colors of 6$\\times$9 stickers.\n",
    "\n",
    "We employ [Quarter-Turn Metric](https://www.speedsolving.com/wiki/index.php/Metric#QTM) (90° turns count as one move; 180°, two) for both scrambling and solving the puzzle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JlekyJyMZn5-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Cube(object):\n",
    "    \"\"\"\n",
    "    A class for 3x3x3 Rubik's Cube\n",
    "    \"\"\"\n",
    "    def __init__(self, metric=METRIC):\n",
    "        self.DTYPE = np.int64\n",
    "        self.metric = metric\n",
    "\n",
    "        # define state and goal\n",
    "        self.reset()  # state\n",
    "        self.goal = np.arange(0, 9 * 6, dtype=self.DTYPE) // 9\n",
    "\n",
    "        # define moves\n",
    "        ## faces and turns\n",
    "        faces = [\"U\", \"D\", \"L\", \"R\", \"B\", \"F\"]\n",
    "        ## [90 degrees clockwise, 90 degrees counter-clockwise]\n",
    "        degrees = [\"\", \"'\"]\n",
    "        degrees_inference = degrees[::-1]\n",
    "        if self.metric == \"HTM\":\n",
    "            # += [180 degrees]\n",
    "            degrees += [\"2\"]\n",
    "            degrees_inference += [\"2\"]\n",
    "        else:\n",
    "            assert self.metric == \"QTM\"\n",
    "        self.moves = [f\"{f}{n}\" for f in faces for n in degrees]\n",
    "        self.moves_inference = [f\"{f}{n}\" for f in faces for n in degrees_inference]\n",
    "\n",
    "        # opposite faces\n",
    "        self.pairing = {\n",
    "            \"R\": \"L\",\n",
    "            \"L\": \"R\",\n",
    "            \"F\": \"B\",\n",
    "            \"B\": \"F\",\n",
    "            \"U\": \"D\",\n",
    "            \"D\": \"U\",\n",
    "        }\n",
    "        # prohibit obviously reduntant moves. \n",
    "        if self.metric == \"HTM\":\n",
    "            # two subsequent moves on the same face (cancelling or redundant).\n",
    "            self.moves_available_after = {\n",
    "                m: [v for v in self.moves if v[0] != m[0]] for m in self.moves\n",
    "            }\n",
    "        elif self.metric == \"QTM\":\n",
    "            # self-cancelling moves on the same face\n",
    "            self.moves_available_after = {\n",
    "                m: [v for v in self.moves if v[0] != m[0]] + [m] for m in self.moves\n",
    "            }\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "        # vectorize the sticker group replacement operations\n",
    "        self.__vectorize_moves()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.arange(0, 9 * 6, dtype=self.DTYPE) // 9\n",
    "\n",
    "    def is_solved(self):\n",
    "        return np.all(self.state == self.goal)\n",
    "\n",
    "    def state_to_batch(self):\n",
    "        return np.expand_dims(self.state, axis=0)\n",
    "\n",
    "    def finger(self, move):\n",
    "        self.state[self.sticker_target[move]] = self.state[self.sticker_source[move]]\n",
    "\n",
    "    def scrambler(self, scramble_length):\n",
    "        \"\"\"\n",
    "        A generator function yielding the state and scramble\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # reset the self.state, scramble, and retun self.state and scramble moves\n",
    "            self.reset()\n",
    "            scramble = []\n",
    "\n",
    "            for i in range(scramble_length):\n",
    "                if i:\n",
    "                    last_move = scramble[-1]\n",
    "                    if i > 1:  # N(>=3)th moves\n",
    "                        while True:\n",
    "                            move = random.choice(self.moves_available_after[last_move])\n",
    "                            if self.metric == \"QTM\":\n",
    "                                if scramble[-2] == last_move == move:\n",
    "                                    # Two mutually canceling moves in a row\n",
    "                                    continue\n",
    "                                elif (\n",
    "                                    scramble[-2][0] == move[0]\n",
    "                                    and len(scramble[-2] + move) == 3\n",
    "                                    and last_move[0] == self.pairing[move[0]]\n",
    "                                ):\n",
    "                                    # Two mutually canceling moves sandwiching an opposite face move\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    break\n",
    "                            elif self.metric == \"HTM\":\n",
    "                                if scramble[-2][0] == move[0] and last_move[0] == self.pairing[move[0]]:\n",
    "                                    # Two mutually canceling moves sandwiching an opposite face move\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    break\n",
    "                            else:\n",
    "                                raise\n",
    "                    else:  # 2nd move\n",
    "                        move = random.choice(self.moves_available_after[last_move])\n",
    "                else:  # 1st move\n",
    "                    move = random.choice(self.moves)\n",
    "\n",
    "                self.finger(move)\n",
    "                scramble.append(move)\n",
    "\n",
    "                yield self.state, move\n",
    "                \n",
    "    def sequence(self, move_list):\n",
    "        for move in move_list:\n",
    "            self.finger(move)\n",
    "\n",
    "    def __vectorize_moves(self):\n",
    "        \"\"\"\n",
    "        This method defines ```self.sticker_target``` and ```self.sticker_source``` to manage sticker colors (target is replaced by source).\n",
    "        They define indices of target and source stickers so that the moves can be vectorized.\n",
    "\n",
    "        colors:\n",
    "                0 0 0\n",
    "                0 0 0\n",
    "                0 0 0\n",
    "            2 2 2 5 5 5 3 3 3 4 4 4\n",
    "            2 2 2 5 5 5 3 3 3 4 4 4\n",
    "            2 2 2 5 5 5 3 3 3 4 4 4\n",
    "                1 1 1\n",
    "                1 1 1\n",
    "                1 1 1\n",
    "        order of stickers on each face:\n",
    "             2  5  8\n",
    "             1  4  7\n",
    "            [0] 3  6\n",
    "\n",
    "        indices of state (each starting with 9*(n-1)):\n",
    "                         2   5   8\n",
    "                         1   4   7\n",
    "                        [0]  3   6\n",
    "             20  23 26  47  50  53  29  32 35  38  41 44\n",
    "             19  22 25  46  49  52  28  31 34  37  40 43\n",
    "            [18] 21 24 [45] 48  51 [27] 30 33 [36] 39 42\n",
    "                        11   14 17\n",
    "                        10   13 16\n",
    "                        [9]  12 15\n",
    "        \"\"\"\n",
    "        self.sticker_target, self.sticker_source = dict(), dict()\n",
    "\n",
    "        self.sticker_replacement = {\n",
    "            # Sticker A is replaced by another sticker at index B -> A:B\n",
    "            \"U\": {\n",
    "                0: 6,\n",
    "                1: 3,\n",
    "                2: 0,\n",
    "                3: 7,\n",
    "                5: 1,\n",
    "                6: 8,\n",
    "                7: 5,\n",
    "                8: 2,\n",
    "                20: 47,\n",
    "                23: 50,\n",
    "                26: 53,\n",
    "                29: 38,\n",
    "                32: 41,\n",
    "                35: 44,\n",
    "                38: 20,\n",
    "                41: 23,\n",
    "                44: 26,\n",
    "                47: 29,\n",
    "                50: 32,\n",
    "                53: 35,\n",
    "            },\n",
    "            \"D\": {\n",
    "                9: 15,\n",
    "                10: 12,\n",
    "                11: 9,\n",
    "                12: 16,\n",
    "                14: 10,\n",
    "                15: 17,\n",
    "                16: 14,\n",
    "                17: 11,\n",
    "                18: 36,\n",
    "                21: 39,\n",
    "                24: 42,\n",
    "                27: 45,\n",
    "                30: 48,\n",
    "                33: 51,\n",
    "                36: 27,\n",
    "                39: 30,\n",
    "                42: 33,\n",
    "                45: 18,\n",
    "                48: 21,\n",
    "                51: 24,\n",
    "            },\n",
    "            \"L\": {\n",
    "                0: 44,\n",
    "                1: 43,\n",
    "                2: 42,\n",
    "                9: 45,\n",
    "                10: 46,\n",
    "                11: 47,\n",
    "                18: 24,\n",
    "                19: 21,\n",
    "                20: 18,\n",
    "                21: 25,\n",
    "                23: 19,\n",
    "                24: 26,\n",
    "                25: 23,\n",
    "                26: 20,\n",
    "                42: 11,\n",
    "                43: 10,\n",
    "                44: 9,\n",
    "                45: 0,\n",
    "                46: 1,\n",
    "                47: 2,\n",
    "            },\n",
    "            \"R\": {\n",
    "                6: 51,\n",
    "                7: 52,\n",
    "                8: 53,\n",
    "                15: 38,\n",
    "                16: 37,\n",
    "                17: 36,\n",
    "                27: 33,\n",
    "                28: 30,\n",
    "                29: 27,\n",
    "                30: 34,\n",
    "                32: 28,\n",
    "                33: 35,\n",
    "                34: 32,\n",
    "                35: 29,\n",
    "                36: 8,\n",
    "                37: 7,\n",
    "                38: 6,\n",
    "                51: 15,\n",
    "                52: 16,\n",
    "                53: 17,\n",
    "            },\n",
    "            \"B\": {\n",
    "                2: 35,\n",
    "                5: 34,\n",
    "                8: 33,\n",
    "                9: 20,\n",
    "                12: 19,\n",
    "                15: 18,\n",
    "                18: 2,\n",
    "                19: 5,\n",
    "                20: 8,\n",
    "                33: 9,\n",
    "                34: 12,\n",
    "                35: 15,\n",
    "                36: 42,\n",
    "                37: 39,\n",
    "                38: 36,\n",
    "                39: 43,\n",
    "                41: 37,\n",
    "                42: 44,\n",
    "                43: 41,\n",
    "                44: 38,\n",
    "            },\n",
    "            \"F\": {\n",
    "                0: 24,\n",
    "                3: 25,\n",
    "                6: 26,\n",
    "                11: 27,\n",
    "                14: 28,\n",
    "                17: 29,\n",
    "                24: 17,\n",
    "                25: 14,\n",
    "                26: 11,\n",
    "                27: 6,\n",
    "                28: 3,\n",
    "                29: 0,\n",
    "                45: 51,\n",
    "                46: 48,\n",
    "                47: 45,\n",
    "                48: 52,\n",
    "                50: 46,\n",
    "                51: 53,\n",
    "                52: 50,\n",
    "                53: 47,\n",
    "            },\n",
    "        }\n",
    "        for m in self.moves:\n",
    "            if len(m) == 1:\n",
    "                assert m in self.sticker_replacement\n",
    "            else:\n",
    "                if \"'\" in m:\n",
    "                    self.sticker_replacement[m] = {\n",
    "                        v: k for k, v in self.sticker_replacement[m[0]].items()\n",
    "                    }\n",
    "                elif \"2\" in m:\n",
    "                    self.sticker_replacement[m] = {\n",
    "                        k: self.sticker_replacement[m[0]][v]\n",
    "                        for k, v in self.sticker_replacement[m[0]].items()\n",
    "                    }\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "            self.sticker_target[m] = list(self.sticker_replacement[m].keys())\n",
    "            self.sticker_source[m] = list(self.sticker_replacement[m].values())\n",
    "\n",
    "            for i, idx in enumerate(self.sticker_target[m]):\n",
    "                assert self.sticker_replacement[m][idx] == self.sticker_source[m][i]\n",
    "\n",
    "\n",
    "cube = Cube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC07rUp8Zn6F"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DxeH2XPVZn6G"
   },
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer with ReLU and BatchNorm\n",
    "    \"\"\"\n",
    "    def __init__(self, input_prev, embed_dim):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_prev, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linearblock_1 = LinearBlock(embed_dim, embed_dim)\n",
    "        self.linearblock_2 = LinearBlock(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.linearblock_1(x)\n",
    "        x = self.linearblock_2(x)\n",
    "        x += inputs # skip-connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.one_hot = nn.functional.one_hot\n",
    "        self.Stack = nn.Sequential(\n",
    "            LinearBlock(324, 5000),\n",
    "            LinearBlock(5000, 1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "            ResidualBlock(1000),\n",
    "        )\n",
    "        self.Prediction = nn.Linear(1000, len(cube.moves))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.one_hot(x.to(torch.int64), num_classes=6).to(torch.float).reshape(-1, 324)\n",
    "        x = self.Stack(x)\n",
    "        logits = self.Prediction(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = Model().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl2aML3wZn6I"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C3wUuY2NZn6J"
   },
   "outputs": [],
   "source": [
    "def batch_generator(\n",
    "        batch_size_per_depth,\n",
    "        scramble_length=SCRAMBLE_LENGTH,\n",
    "        n_jobs=multiprocessing.cpu_count(),\n",
    "    ):\n",
    "    # setup\n",
    "    __dtype = np.int64\n",
    "    batch_size = batch_size_per_depth * scramble_length\n",
    "    # multiprocessing\n",
    "    cubes = [Cube()] * n_jobs\n",
    "    generators = [c.scrambler(scramble_length=scramble_length) for c in cubes]\n",
    "\n",
    "    global get_minibatch\n",
    "\n",
    "    def get_minibatch(i):\n",
    "        states = np.zeros((scramble_length, 9 * 6), dtype=__dtype)\n",
    "        last_moves = np.zeros((scramble_length,), dtype=__dtype)\n",
    "        g_local = generators[i % n_jobs]\n",
    "        for j in range(scramble_length):\n",
    "            _, last_move = next(g_local)\n",
    "            states[j, :] = cubes[i % n_jobs].state  # _to_numpy()\n",
    "            last_moves[j] = cube.moves.index(last_move)\n",
    "\n",
    "        return states, last_moves\n",
    "\n",
    "    # create the Pool instance after ```defining cubes``` and ```get_minibatch```\n",
    "    p = multiprocessing.Pool(n_jobs)\n",
    "    for _ in iter(int, 1):\n",
    "        ret = p.map(get_minibatch, list(range(batch_size_per_depth)))\n",
    "        batch_x = np.concatenate([e[0] for e in ret])\n",
    "        batch_y = np.concatenate([e[1] for e in ret], axis=0)\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andri\\AppData\\Local\\Temp\\ipykernel_8772\\2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object batch_generator at 0x000001CB7B5EDFC0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_generator(\n",
    "        batch_size_per_depth=TrainConfig.batch_size_per_depth,\n",
    "        scramble_length=TrainConfig.scramble_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ = next(batch_generator(\n",
    "#         batch_size_per_depth=TrainConfig.batch_size_per_depth,\n",
    "#         scramble_length=TrainConfig.scramble_length,\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (Stack): Sequential(\n",
       "    (0): LinearBlock(\n",
       "      (fc): Linear(in_features=324, out_features=5000, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (fc): Linear(in_features=5000, out_features=1000, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Prediction): Linear(in_features=1000, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.from_numpy(input_[0][0:5000]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(torch.from_numpy(input_[0][0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vzSzqL74Zn6L"
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    BATCH_SIZE = config.batch_size_per_depth * config.scramble_length\n",
    "    scramble_length = config.scramble_length\n",
    "    g = batch_generator(\n",
    "        batch_size_per_depth=config.batch_size_per_depth,\n",
    "        scramble_length=config.scramble_length,\n",
    "    )\n",
    "    h = []\n",
    "\n",
    "    for i in trange(1, config.num_train_steps + 1, smoothing=0):\n",
    "        # prep\n",
    "        batch_x, batch_y = next(g)\n",
    "        batch_x, batch_y = torch.from_numpy(batch_x).to(device), torch.from_numpy(\n",
    "            batch_y\n",
    "        ).to(device)\n",
    "\n",
    "        # update\n",
    "        pred_y = model(batch_x)\n",
    "        loss = loss_fn(pred_y, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        h.append(loss.item())\n",
    "        if config.interval_steps_plot and i % config.interval_steps_plot == 0:\n",
    "            clear_output()\n",
    "            plt_history(h)\n",
    "        if config.interval_steps_save and i % config.interval_steps_save == 0:\n",
    "            torch.save(model.state_dict(), f\"{METRIC}-model_{i}steps.pth\")\n",
    "            print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cube.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "l3lCB5_lZn6N",
    "outputId": "d7787bc9-9711-4778-9db1-3972faad1aa4"
   },
   "outputs": [],
   "source": [
    "# train(TrainConfig)\n",
    "# print(f\"Trained on data equivalent to {TrainConfig.batch_size_per_depth * TrainConfig.num_train_steps} solves.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('QTM-model_1000000steps.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (Stack): Sequential(\n",
       "    (0): LinearBlock(\n",
       "      (fc): Linear(in_features=324, out_features=5000, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (fc): Linear(in_features=5000, out_features=1000, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (linearblock_1): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (linearblock_2): LinearBlock(\n",
       "        (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Prediction): Linear(in_features=1000, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oijzxgzoZn6O"
   },
   "source": [
    "## Inference\n",
    "\n",
    "We test and compare on the DeepCubeA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "6JO-ECCqZn6P"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4pkjY3OZn6Q"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cocDX5olZn6R"
   },
   "source": [
    "Download dataset from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOyibmM9Zn6T",
    "outputId": "db6646b3-42cb-4cc2-efb7-dc78b581fcb7"
   },
   "outputs": [],
   "source": [
    "# %cd /content/\n",
    "# !git clone -q https://github.com/forestagostinelli/DeepCubeA\n",
    "# %cd /content/DeepCubeA/\n",
    "# import \n",
    "\n",
    "\n",
    "# print('### Optimal Solver ###')\n",
    "# filename = 'data/cube3/test/data_0.pkl'\n",
    "# with open(filename, 'rb') as f:\n",
    "#     if 'states' in filename:\n",
    "#         data_Optimal = pickle.load(f, encoding='iso-8859-1')\n",
    "#     else:\n",
    "#         data_Optimal = pickle.load(f)\n",
    "\n",
    "# print(data_Optimal.keys())\n",
    "# solutions_Optimal, times_Optimal, num_nodes_Optimal = [\n",
    "#     data_Optimal[e] for e in ['solutions', 'times', 'num_nodes_generated']]\n",
    "# len_Optimal = [len(s) for s in solutions_Optimal]\n",
    "# len_Optimal_count = {i: len_Optimal.count(\n",
    "#     i) for i in range(min(len_Optimal), max(len_Optimal))}\n",
    "\n",
    "# print('No. of cases:', len(len_Optimal))\n",
    "\n",
    "# print('\\n### Optimal Solver ###')\n",
    "\n",
    "# filename = 'results/cube3/results.pkl'\n",
    "# with open(filename, 'rb') as f:\n",
    "#     if 'states' in filename:\n",
    "#         data_DeepCubeA = pickle.load(f, encoding='iso-8859-1')\n",
    "#     else:\n",
    "#         data_DeepCubeA = pickle.load(f)\n",
    "\n",
    "# print(data_DeepCubeA.keys())\n",
    "# solutions_DeepCubeA, times_DeepCubeA, num_nodes_DeepCubeA = [\n",
    "#     data_DeepCubeA[e] for e in ['solutions', 'times', 'num_nodes_generated']]\n",
    "# len_DeepCubeA = [len(s) for s in solutions_DeepCubeA]\n",
    "# len_DeepCubeA_count = {i: len_DeepCubeA.count(\n",
    "#     i) for i in range(min(len_DeepCubeA), max(len_DeepCubeA))}\n",
    "\n",
    "# print('No. of cases:', len(solutions_DeepCubeA))\n",
    "\n",
    "# %cd /content/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x05udFo4Zn6V"
   },
   "source": [
    "Convert optimal solutions to test scrambles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVv4g6VrZn6W",
    "outputId": "04e006d1-1f4f-4705-bed8-46e07dcd180f"
   },
   "outputs": [],
   "source": [
    "# # scrambles are the inverse of the optimal solutions\n",
    "# def solution2scramble(solution):\n",
    "#     return [m[0] if m[1] == -1 else m[0] + \"'\" for m in solution[::-1]]\n",
    "\n",
    "# test_scrambles = [solution2scramble(s) for s in solutions_Optimal]\n",
    "\n",
    "# print(f\"\"\"Example: {solutions_Optimal[0]} -> {test_scrambles[0]}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk6u5qNuZn6X"
   },
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EXC3x41qZn6Y"
   },
   "outputs": [],
   "source": [
    "def beam_search(\n",
    "        cube,\n",
    "        top_k,\n",
    "        max_depth,\n",
    "        skip_redundant_moves=True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Beam search algorithm.\n",
    "    Input:\n",
    "        cube: A scrambled Rubik's Cube\n",
    "        top_k: Number of top solutions to return per depth.\n",
    "        max_depth: Maximum depth of the search tree.\n",
    "        skip_redundant_moves: If True, skip redundant moves.\n",
    "    Output: \n",
    "        (move_hist, num_nodes, time_taken): ('first solution found', 'the number of nodes expanded', 'the amount of time')\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # metrics\n",
    "        num_nodes = 0\n",
    "        time_0 = time.time()\n",
    "        # manage candidates by their states and path (list of moves} as ordered lists\n",
    "        candidate_states, candidate_paths = [cube.state], [[]]\n",
    "\n",
    "        # loop until you find a solution OR you reach the maxium depth.\n",
    "        for depth in range(max_depth):\n",
    "            # create a batch of states to to predict for the depth\n",
    "            if depth==0: # the very initial state:\n",
    "                batch_x = cube.state_to_batch()\n",
    "            else: \n",
    "                batch_x = np.zeros((len(candidate_paths), 54), dtype=np.int64)\n",
    "                for i, move_hist in enumerate(candidate_paths):\n",
    "                    # apply the next predicted move\n",
    "                    cube.state = candidate_states[i]\n",
    "                    cube.finger(move_hist[-1])\n",
    "                    num_nodes += 1\n",
    "                    if cube.is_solved():\n",
    "                        time_taken = time.time() - time_0\n",
    "                        return move_hist, num_nodes, time_taken\n",
    "                    # else make prediction, adding it to batch_x\n",
    "                    batch_x[i, :] = deepcopy(cube.state)\n",
    "\n",
    "            # make predictions with the trained DNN\n",
    "            batch_x = torch.from_numpy(batch_x).to(device)\n",
    "            batch_p = model(batch_x).to(\"cpu\").detach().numpy()\n",
    "\n",
    "            # loop over candidate_paths\n",
    "            potential_candidates = []  # storage for the depth-level candidates storing (path, value, index).\n",
    "            for i, move_hist in enumerate(candidate_paths):\n",
    "                prediction_candicate = batch_p[i, :] # output logits for the given state\n",
    "                for ix in range(len(cube.moves)): # iterate over all possible moves.\n",
    "                    p = prediction_candicate[ix] # predicted value to expand the path with the given move.\n",
    "                    m = cube.moves_inference[ix]\n",
    "                    if move_hist:\n",
    "                        if skip_redundant_moves:\n",
    "                            # remove obviously redundant moves.\n",
    "                            if METRIC == \"QTM\":\n",
    "                                if m not in cube.moves_available_after[move_hist[-1]]:\n",
    "                                    # Two mutually canceling moves\n",
    "                                    continue\n",
    "                                elif len(move_hist) == 1:\n",
    "                                    potential_candidates.append((move_hist+[m], p, i))\n",
    "                                else:  # len(move_hist)>1\n",
    "                                    if move_hist[-2] == move_hist[-1] == m:\n",
    "                                        # three subsequent same moves\n",
    "                                        continue\n",
    "                                    elif (\n",
    "                                        move_hist[-2][0] == m[0]\n",
    "                                        and len(move_hist[-2] + m) == 3\n",
    "                                        and move_hist[-1][0] == cube.pairing[m[0]]\n",
    "                                    ):\n",
    "                                        # Two mutually canceling moves sandwiching an opposite face move\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        potential_candidates.append((move_hist+[m], p, i))\n",
    "                            elif METRIC == \"HTM\":\n",
    "                                if m[0] == move_hist[-1][0]:\n",
    "                                    # Two mutually canceling moves\n",
    "                                    continue\n",
    "                                elif len(move_hist) == 1:\n",
    "                                    potential_candidates.append((move_hist+[m], p, i))\n",
    "                                else:  # len(move_hist)>1\n",
    "                                    if move_hist[-2][0] == m[0] and move_hist[-1][0] == cube.pairing[m[0]]:\n",
    "                                        # Two mutually canceling moves sandwiching an opposite face move\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        potential_candidates.append((move_hist+[m], p, i))\n",
    "                            else:\n",
    "                                raise\n",
    "                        else: # the 2nd move\n",
    "                            potential_candidates.append((move_hist+[m], p, i))\n",
    "                    else:\n",
    "                        # the 1st move\n",
    "                        potential_candidates.append(([m], p, i))\n",
    "\n",
    "            # sort potential paths by expected values\n",
    "            potential_candidates = sorted(potential_candidates, key=lambda item: -item[1])\n",
    "            # if the number of candidates exceed that of beam width 'top_k'\n",
    "            if top_k < len(potential_candidates):\n",
    "                potential_candidates = potential_candidates[:top_k]\n",
    "\n",
    "            # renew the candidates\n",
    "            candidate_paths = [e[0] for e in potential_candidates]\n",
    "            candidate_states = [deepcopy(candidate_states[e[2]]) for e in potential_candidates]\n",
    "\n",
    "        # if you reaches the maximum depth, the last expanded nodes are tested.\n",
    "        for i, move_hist in enumerate(candidate_paths):\n",
    "            # apply the next predicted move & check if solved.\n",
    "            cube.state = candidate_states[i]\n",
    "            cube.finger(move_hist[-1])\n",
    "            num_nodes += 1\n",
    "            if cube.is_solved():\n",
    "                time_taken = time.time() - time_0\n",
    "                return move_hist, num_nodes, time_taken\n",
    "\n",
    "        # if you DO NOT find any solution with the given configuration, return None's\n",
    "        print(\"Solution not found.\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.reset(), cube.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " array([3, 0, 0, 2, 0, 4, 4, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 0, 2, 0, 2, 5,\n",
       "        2, 5, 5, 1, 0, 2, 0, 3, 4, 3, 5, 3, 3, 3, 4, 4, 5, 2, 4, 2, 4, 4,\n",
       "        4, 1, 3, 5, 5, 5, 0, 5, 3, 0]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.sequence([\"U'\",\"L'\", 'D',\"U'\",\"L'\", 'D',\"U'\",\"L'\", 'D', 'F']), cube.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.state = np.array([2,5,0,0,0,3,3,4,1,\n",
    "        0,3,0,0,1,5,2,2,1,\n",
    "        3,2,5,1,2,0,3,3,1,\n",
    "        2,4,4,1,3,1,4,4,3,\n",
    "        0,2,5,2,4,0,4,5,2,\n",
    "        5,5,5,1,5,4,4,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"R'\", 'B', \"F'\", \"R'\", 'D', \"R'\", \"B'\", 'U', 'D', 'L', \"F'\", 'L', 'B', \"L'\", \"D'\", 'B', 'R', 'D', 'R', 'U', 'R', 'U', \"R'\"]\n"
     ]
    }
   ],
   "source": [
    "result = beam_search(cube, top_k, max_depth)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rBfrDrbUDLfLBldBRDRURUr\n"
     ]
    }
   ],
   "source": [
    "def transformar_letras(cadena):\n",
    "    # Crear una lista para almacenar los resultados transformados\n",
    "    nueva_lista = []\n",
    "    \n",
    "    # Iterar sobre cada elemento de la lista\n",
    "    for elemento in cadena:\n",
    "        # Si el elemento contiene \"'\", se elimina y se convierte a minúsculas\n",
    "        if \"'\" in elemento:\n",
    "            nuevo_elemento = elemento.replace(\"'\", \"\").lower()\n",
    "        else:\n",
    "            nuevo_elemento = elemento\n",
    "        # Agregar el elemento transformado a la nueva lista\n",
    "        nueva_lista.append(nuevo_elemento)\n",
    "    \n",
    "    # Concatenar todas las letras en una sola línea\n",
    "    nueva_cadena = ''.join(nueva_lista)\n",
    "    \n",
    "    return nueva_cadena\n",
    "\n",
    "resultado = transformar_letras(result[0])\n",
    "print(resultado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtAhlo21Zn6b",
    "tags": []
   },
   "source": [
    "### Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "8gCrRuCZZn6c",
    "outputId": "0ed62f18-19a9-48b2-a56a-d0d92e57730b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     cube\u001b[38;5;241m.\u001b[39mfinger(scramble_move)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# solve\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m solution, num_nodes, time_taken \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcube\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_nodes:\n\u001b[1;32m     11\u001b[0m     solutions_all\u001b[38;5;241m.\u001b[39mappend(solution)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mbeam_search\u001b[0;34m(cube, top_k, max_depth, skip_redundant_moves)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# make predictions with the trained DNN\u001b[39;00m\n\u001b[1;32m     43\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(batch_x)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 44\u001b[0m batch_p \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# loop over candidate_paths\u001b[39;00m\n\u001b[1;32m     47\u001b[0m potential_candidates \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# storage for the depth-level candidates storing (path, value, index).\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mone_hot(x, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m324\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPrediction(x)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mLinearBlock.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "# solutions_all, num_nodes_all, times_all = [], [], []\n",
    "\n",
    "# for scramble in tqdm(test_scrambles, position=0):\n",
    "#     # reset and scramble\n",
    "#     cube.reset()\n",
    "#     for scramble_move in scramble:\n",
    "#         cube.finger(scramble_move)\n",
    "#     # solve\n",
    "#     solution, num_nodes, time_taken = beam_search(cube, top_k, max_depth)\n",
    "#     if num_nodes:\n",
    "#         solutions_all.append(solution)\n",
    "#         num_nodes_all.append(num_nodes)\n",
    "#         times_all.append(time_taken)\n",
    "\n",
    "# plot_result(solutions_all, num_nodes_all, times_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TbIbL00Zn6l"
   },
   "source": [
    "## Comparison to DeepCubeA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39qzxslFZn6m"
   },
   "source": [
    "### Solution length vs No. of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQ6W6kL5Zn6n"
   },
   "outputs": [],
   "source": [
    "# num_nodes_ours = [e for e in num_nodes_all if e]\n",
    "# num_nodes_ours = [e for e in num_nodes_all if e]\n",
    "# times_ours = [e for e in times_all if e]\n",
    "# len_ours = [len(e) for e in solutions_all if e]\n",
    "# len_ours_count = {i: len_ours.count(i) for i in range(min(len_ours), max(len_ours))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "xGT_G03mZn6o",
    "outputId": "ca905882-4366-479c-862c-e2bb216c1809"
   },
   "outputs": [],
   "source": [
    "# left, width = 0.12, 0.75\n",
    "# bottom, height = 0.1, 0.75\n",
    "# spacing = 0.0\n",
    "\n",
    "# rect_scatter = [left, bottom, width, height]\n",
    "# rect_histx = [left, bottom + height, width, 0.1]\n",
    "# rect_histy = [left + width, bottom, 0.1, height]\n",
    "\n",
    "# fig = plt.figure(figsize=(7.5, 7.5))\n",
    "# ax = fig.add_axes(rect_scatter)\n",
    "# ax.set_xlabel(\"Solution length\")\n",
    "# ax.set_ylabel(\"No. of nodes\")\n",
    "# ax.set_yscale(\"log\")\n",
    "# ax_histx = fig.add_axes(rect_histx, sharex=ax)\n",
    "# ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "# ax_histx.set_ylabel(\"Frequency\")\n",
    "# ax_histy.set_xlabel(\"Frequency\")\n",
    "# ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "# ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "# ax.set_xlim(15, max(len_ours))\n",
    "# ax_histx.set_xlim(15, max(len_ours))\n",
    "\n",
    "# ymax = 8.25\n",
    "# ax.set_ylim(10**2.5, 10**ymax)\n",
    "# ax_histy.set_ylim(10**2.5, 10**ymax)\n",
    "# bins_x = np.logspace(2.5, ymax, 100)\n",
    "\n",
    "# for k, (y, x) in {\n",
    "#         \"Optimal\": (num_nodes_Optimal, len_Optimal),\n",
    "#         \"DeepCubeA\": (num_nodes_DeepCubeA, len_DeepCubeA),\n",
    "#         \"Ours\": (num_nodes_ours, len_ours),\n",
    "#     }.items():\n",
    "#     ax.scatter(x, y, label=k, s=10)\n",
    "#     if k == \"Optimal\":\n",
    "#         ax_histy.hist(y, bins=bins_x, orientation=\"horizontal\")\n",
    "#     else:\n",
    "#         ax_histy.hist(y, bins=bins_x, orientation=\"horizontal\")\n",
    "\n",
    "# for i, d in enumerate([len_Optimal_count, len_DeepCubeA_count, len_ours_count]):\n",
    "#     if i:\n",
    "#         ax_histx.bar(list(d.keys()), list(d.values()), width=1)\n",
    "#     else:\n",
    "#         ax_histx.bar(list(d.keys()), list(d.values()), width=1.0)\n",
    "\n",
    "# ax_histx.axvline(np.mean(len_ours), color=\"#EB4275\")\n",
    "# ax.axvline(np.mean(len_ours), color=\"#EB4275\")\n",
    "\n",
    "# ax.plot(np.mean(len_Optimal), np.mean(num_nodes_Optimal), \"x\", markersize=10)\n",
    "# ax.plot(np.mean(len_DeepCubeA), np.mean(num_nodes_DeepCubeA), \"x\", markersize=10)\n",
    "# ax.plot(np.mean(len_ours), np.mean(num_nodes_ours), \"x\", label=\"Ours\", markersize=10)\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOJazVV9Zn6q"
   },
   "source": [
    "### Calculation time (s) vs. Solution length\n",
    "\n",
    "We compare time taken to solve test cases. \n",
    "\n",
    "In order to compare fairly our method to DeepCubeA, both of which are DNN-based, we obtain per-node time (s) and adjust ours to DeepCubeA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "02BUoAohZn6r",
    "outputId": "a11809a0-2554-4c2e-f6c9-14440525baf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal:\t1.4801182995895741e-06\n",
      "DeepCubeA:\t9.073204353441794e-06\n",
      "Ours:\t9.461254480153633e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "# ax.set_xlabel(\"Calculation time per node (s)\")\n",
    "# ax.set_ylabel(\"Frequency\")\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_xlim(10**-6.5, 10**-3.75)\n",
    "# bins_x = np.logspace(-6.5, -3.75, 100)\n",
    "# for k, (n, t, s) in {\n",
    "#         \"Optimal\": (num_nodes_Optimal, times_Optimal, len_Optimal),\n",
    "#         \"DeepCubeA\": (num_nodes_DeepCubeA, times_DeepCubeA, len_DeepCubeA),\n",
    "#         \"Ours\": (num_nodes_ours, times_ours, len_ours),\n",
    "#     }.items():\n",
    "#     time_per_node = np.array(t) / np.array(n)\n",
    "#     ax.hist(time_per_node, bins=bins_x, label=k)\n",
    "#     print(f\"{k}:\\t{np.mean(time_per_node)}\")\n",
    "# ax.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uaitQt9PZn6t",
    "outputId": "f5810628-0252-44c2-96af-095b60374989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.42768807093454"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t_per_node_DeepCubeA = np.array(times_DeepCubeA) / np.array(num_nodes_DeepCubeA)\n",
    "# t_per_node_Ours = np.array(times_ours) / np.array(num_nodes_ours)\n",
    "# t_ratio = np.mean(t_per_node_Ours) / np.mean(t_per_node_DeepCubeA)\n",
    "# t_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "IndXIKjxZn6u",
    "outputId": "0b03b5da-6def-49f8-e4c9-e80382eb99c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# left, width = 0.125, 0.35\n",
    "# bottom, height = 0.135, 0.70\n",
    "\n",
    "# rect_scatter = [left, bottom, width, height]\n",
    "# rect_scatter_j = [left + width, bottom, width, height]\n",
    "# rect_histx_0 = [left, bottom + height, width, 0.10]\n",
    "# rect_histx_1 = [left + width, bottom + height, width, 0.10]\n",
    "# rect_histy = [left + 2 * (width), bottom, 0.125, height]\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# ax = fig.add_axes(rect_scatter)\n",
    "# ax.set_xlabel(\"Actual time taken (s)\")\n",
    "# ax.set_ylabel(\"Solution lengths\")\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax_j = fig.add_axes(rect_scatter_j)\n",
    "# ax_j.set_xlabel(\"Normalized time taken (s)\")\n",
    "# ax_j.set_xscale(\"log\")\n",
    "# ax_j.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "# ax_histx_0 = fig.add_axes(rect_histx_0, sharex=ax)\n",
    "# ax_histx_0.set_ylabel(\"Frequency\")\n",
    "# ax_histx_0.tick_params(axis=\"x\", labelbottom=False)\n",
    "# ax_histx_1 = fig.add_axes(rect_histx_1, sharex=ax)\n",
    "# ax_histx_1.tick_params(axis=\"x\", labelbottom=False)\n",
    "# ax_histx_1.tick_params(axis=\"y\", labelleft=False)\n",
    "# ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "# ax_histy.set_xlabel(\"Frequency\")\n",
    "# ax_histy.tick_params(axis=\"y\", labelleft=True)\n",
    "\n",
    "# bins_x = np.logspace(-3.5, 3.25, 100)\n",
    "# for k, (t, s) in {\n",
    "#         \"Optimal\": (times_Optimal, len_Optimal),\n",
    "#         \"DeepCubeA\": (times_DeepCubeA, len_DeepCubeA),\n",
    "#         \"Ours\": (times_ours, len_ours),\n",
    "#     }.items():\n",
    "#     ax.scatter(t, s, label=k, s=5)\n",
    "#     if k == \"Optimal\":\n",
    "#         ax_histx_0.hist(t, bins=bins_x)\n",
    "#     else:\n",
    "#         ax_histx_0.hist(t, bins=bins_x)\n",
    "#     if k == \"Ours\":\n",
    "#         t_just = np.array(t) / t_ratio\n",
    "#         ax_histx_1.hist(t_just, bins=bins_x)\n",
    "#         ax_j.scatter(t_just, s, label=k, s=5)\n",
    "#     else:\n",
    "#         if k == \"Optimal\":\n",
    "#             ax_histx_1.hist(np.array(t), bins=bins_x,)\n",
    "#         else:\n",
    "#             ax_histx_1.hist(np.array(t), bins=bins_x)\n",
    "#         ax_j.scatter(np.array(t), s, label=k, s=5)\n",
    "\n",
    "# for AX in [ax, ax_j]:\n",
    "#     AX.plot(np.mean(times_Optimal), np.mean(len_Optimal), \"x\", markersize=10)\n",
    "#     AX.plot(np.mean(times_DeepCubeA), np.mean(len_DeepCubeA), \"x\", markersize=10)\n",
    "#     AX.set_xlim(10**-3.5, 10**3.25)\n",
    "#     AX.set_ylim(15.5, max(len_ours) + 1)\n",
    "\n",
    "# for AX in [ax, ax_j, ax_histy]:\n",
    "#     AX.axhline(np.mean(len_ours), color=\"#EB4275\")\n",
    "\n",
    "# for i, d in enumerate([len_Optimal_count, len_DeepCubeA_count, len_ours_count]):\n",
    "#     if i:\n",
    "#         ax_histy.barh(list(d.keys()), list(d.values()), height=1)\n",
    "#     else:\n",
    "#         ax_histy.barh(list(d.keys()), list(d.values()), height=1)\n",
    "\n",
    "\n",
    "# ax.plot(np.mean(times_ours), np.mean(len_ours), \"x\", markersize=20)\n",
    "# ax_j.plot(np.mean(times_ours) / t_ratio, np.mean(len_ours), \"x\", markersize=20)\n",
    "\n",
    "# ax.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "t8ItwXquZn59"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
